{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/daskoushik/scratch-mlp?scriptVersionId=114014082\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"4cfdc5b4","metadata":{"papermill":{"duration":0.005762,"end_time":"2022-12-16T18:28:32.558289","exception":false,"start_time":"2022-12-16T18:28:32.552527","status":"completed"},"tags":[]},"source":["# Packages"]},{"cell_type":"code","execution_count":1,"id":"02413ea4","metadata":{"execution":{"iopub.execute_input":"2022-12-16T18:28:32.569095Z","iopub.status.busy":"2022-12-16T18:28:32.568575Z","iopub.status.idle":"2022-12-16T18:28:32.580164Z","shell.execute_reply":"2022-12-16T18:28:32.579122Z"},"papermill":{"duration":0.019507,"end_time":"2022-12-16T18:28:32.582464","exception":false,"start_time":"2022-12-16T18:28:32.562957","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","id":"f58befd9","metadata":{"papermill":{"duration":0.003821,"end_time":"2022-12-16T18:28:32.590674","exception":false,"start_time":"2022-12-16T18:28:32.586853","status":"completed"},"tags":[]},"source":["# Activation functions"]},{"cell_type":"code","execution_count":2,"id":"51049d2e","metadata":{"execution":{"iopub.execute_input":"2022-12-16T18:28:32.600725Z","iopub.status.busy":"2022-12-16T18:28:32.599724Z","iopub.status.idle":"2022-12-16T18:28:32.606626Z","shell.execute_reply":"2022-12-16T18:28:32.605817Z"},"papermill":{"duration":0.014167,"end_time":"2022-12-16T18:28:32.608667","exception":false,"start_time":"2022-12-16T18:28:32.5945","status":"completed"},"tags":[]},"outputs":[],"source":["def sigmoid(z):\n","    return 1 / (1 + np.exp(-z))\n","def relu(z):\n","    return np.maximum(0, z)\n","def tanh(z):\n","    return np.tanh(z)\n","def softmax(z):\n","    return (np.exp(z - np.max(z)) / np.exp(z - np.max(z)).sum())"]},{"cell_type":"markdown","id":"3ce37eca","metadata":{"papermill":{"duration":0.003751,"end_time":"2022-12-16T18:28:32.616502","exception":false,"start_time":"2022-12-16T18:28:32.612751","status":"completed"},"tags":[]},"source":["# Model helper functions:\n","\n","* **initialize_parameters** - initializes at random the parameters weights and biases\n","* **forward_propagation** - for linear->activation forward prop\n","* **L_forward_propagation** - for L layers - hidden: linear->activation_hidden, linear->activation_output\n","* **compute_cost** - cross-entropy loss\n","* **linear_backward_propagation** - each layer linear back prop\n","* **activation_backward_propagation** - each layer activation back prop\n","* **L_backward_propagation** - for L layers back prop\n","* **update_parameters** - update the parameters"]},{"cell_type":"code","execution_count":3,"id":"49e8bfaa","metadata":{"execution":{"iopub.execute_input":"2022-12-16T18:28:32.626133Z","iopub.status.busy":"2022-12-16T18:28:32.62578Z","iopub.status.idle":"2022-12-16T18:28:32.632288Z","shell.execute_reply":"2022-12-16T18:28:32.631289Z"},"papermill":{"duration":0.01374,"end_time":"2022-12-16T18:28:32.634299","exception":false,"start_time":"2022-12-16T18:28:32.620559","status":"completed"},"tags":[]},"outputs":[],"source":["def initialize_parameters(layer_dims):\n","    \"\"\"\n","    Inputs:\n","    layer_dims - list of number of neurons in each layer\n","    Returns:\n","    Wl - Weight matrix of shape (layer_dims[l], layer_dims[l-1])\n","    b1 - Bias vector of shape (layer_dims[l], 1)\n","    \"\"\"\n","    parameters = {}\n","    L = len(layer_dims) # total no. of layers\n","    \n","    for l in range(1, L):\n","        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n","        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n","    \n","    return parameters"]},{"cell_type":"code","execution_count":4,"id":"d9ef297f","metadata":{"execution":{"iopub.execute_input":"2022-12-16T18:28:32.643615Z","iopub.status.busy":"2022-12-16T18:28:32.643118Z","iopub.status.idle":"2022-12-16T18:28:32.656057Z","shell.execute_reply":"2022-12-16T18:28:32.655337Z"},"papermill":{"duration":0.019831,"end_time":"2022-12-16T18:28:32.658099","exception":false,"start_time":"2022-12-16T18:28:32.638268","status":"completed"},"tags":[]},"outputs":[],"source":["def forward_propagation(A_prev, W, b, activation):\n","    \"\"\"\n","    Inputs:\n","    A_prev - previous layer activation\n","    W - weight, b - bias\n","    Returns:\n","    A - post-activation\n","    \"\"\"\n","    if activation == \"sigmoid\":\n","        Z = np.dot(W, A_prev) + b\n","        A = sigmoid(Z)\n","        linear_cache = (A_prev, W, b)\n","        activation_cache = Z\n","    \n","    elif activation == \"tanh\":\n","        Z = np.dot(W, A_prev) + b\n","        A = tanh(Z)\n","        linear_cache = (A_prev, W, b)\n","        activation_cache = Z\n","        \n","    elif activation == \"relu\":\n","        Z = np.dot(W, A_prev) + b\n","        A = relu(Z)\n","        linear_cache = (A_prev, W, b)\n","        activation_cache = Z\n","    \n","    elif activation == \"softmax\":\n","        Z = np.dot(W, A_prev) + b\n","        A = softmax(Z)\n","        linear_cache = (A_prev, W, b)\n","        activation_cache = Z\n","        \n","    cache = (linear_cache, activation_cache)\n","    \n","    return A, cache"]},{"cell_type":"code","execution_count":5,"id":"d005b3c0","metadata":{"execution":{"iopub.execute_input":"2022-12-16T18:28:32.667804Z","iopub.status.busy":"2022-12-16T18:28:32.66748Z","iopub.status.idle":"2022-12-16T18:28:32.676341Z","shell.execute_reply":"2022-12-16T18:28:32.675348Z"},"papermill":{"duration":0.016085,"end_time":"2022-12-16T18:28:32.678359","exception":false,"start_time":"2022-12-16T18:28:32.662274","status":"completed"},"tags":[]},"outputs":[],"source":["def L_forward_propagation(X, parameters, activation_hidden, activation_output):\n","    \"\"\"\n","    Inputs:\n","    X - input layer\n","    parameters - weights and biases of L layers\n","    activation_hidden - hidden layer activation function\n","    activation_output - output layer activation function\n","    Returns:\n","    AL - activation of the output layer\n","    caches - linear and activation cache to back propagate easily\n","    \"\"\"\n","    caches = []\n","    A = X\n","    L = len(parameters) // 2\n","    \n","    for l in range(1, L):\n","        A_prev = A\n","        if activation_hidden == 'relu':\n","            A, cache = forward_propagation(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], 'relu')\n","            caches.append(cache)\n","        elif activation_hidden == 'tanh':\n","            A, cache = forward_propagation(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], 'tanh')\n","            caches.append(cache)\n","            \n","    if activation_output == 'softmax':\n","        AL, cache = forward_propagation(A, parameters['W' + str(L)], parameters['b' + str(L)], 'softmax')\n","        caches.append(cache)\n","    elif activation_output == 'sigmoid':\n","        AL, cache = forward_propagation(A, parameters['W' + str(L)], parameters['b' + str(L)], 'sigmoid')\n","        caches.append(cache)\n","    \n","    return AL, caches"]},{"cell_type":"code","execution_count":6,"id":"d215384a","metadata":{"execution":{"iopub.execute_input":"2022-12-16T18:28:32.687912Z","iopub.status.busy":"2022-12-16T18:28:32.687538Z","iopub.status.idle":"2022-12-16T18:28:32.693513Z","shell.execute_reply":"2022-12-16T18:28:32.692498Z"},"papermill":{"duration":0.013081,"end_time":"2022-12-16T18:28:32.695582","exception":false,"start_time":"2022-12-16T18:28:32.682501","status":"completed"},"tags":[]},"outputs":[],"source":["def compute_cost(AL, Y):\n","    \"\"\"\n","    Inputs:\n","    AL - output layer activation\n","    Y - true labels\n","    Returns:\n","    cost - cross-entropy cost\n","    \"\"\"\n","    \n","    m = Y.shape[1]\n","    cost = - (1 / m) * (np.dot(Y, np.log(AL).T) + np.dot(1-Y, np.log(1-AL).T))\n","    cost = np.squeeze(cost)\n","    \n","    return cost"]},{"cell_type":"code","execution_count":7,"id":"433c89ad","metadata":{"execution":{"iopub.execute_input":"2022-12-16T18:28:32.70577Z","iopub.status.busy":"2022-12-16T18:28:32.705429Z","iopub.status.idle":"2022-12-16T18:28:32.712262Z","shell.execute_reply":"2022-12-16T18:28:32.711186Z"},"papermill":{"duration":0.014706,"end_time":"2022-12-16T18:28:32.714336","exception":false,"start_time":"2022-12-16T18:28:32.69963","status":"completed"},"tags":[]},"outputs":[],"source":["def linear_backward_propagation(dZ, cache):\n","    \"\"\"\n","    Inputs:\n","    dZ - Gradient of the cost with respect to Z\n","    cache - (A_prev, W, b) from the forward propapagtion\n","    Returns:\n","    dA_prev - Gradient of the cost w.r.t. A_prev\n","    dW - Gradient of the cost w.r.t. W\n","    db - Gradient of the cost w.r.t. b \n","    \"\"\"\n","    \n","    A_prev, W, b = cache\n","    m = A_prev.shape[1]\n","    \n","    dW = 1 / m * np.dot(dZ, A_prev.T)\n","    db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n","    dA_prev = np.dot(W.T, dZ)\n","    \n","    return dA_prev, dW, db"]},{"cell_type":"code","execution_count":8,"id":"45eee817","metadata":{"execution":{"iopub.execute_input":"2022-12-16T18:28:32.723643Z","iopub.status.busy":"2022-12-16T18:28:32.723315Z","iopub.status.idle":"2022-12-16T18:28:32.73182Z","shell.execute_reply":"2022-12-16T18:28:32.730936Z"},"papermill":{"duration":0.015688,"end_time":"2022-12-16T18:28:32.73407","exception":false,"start_time":"2022-12-16T18:28:32.718382","status":"completed"},"tags":[]},"outputs":[],"source":["def activation_backward_propagation(dA, cache, activation):\n","    \"\"\"\n","    Inputs:\n","    dA - post activation gradient\n","    cache - (linear_cache, activation_cache)\n","    activation - activation function to be used\n","    Returns:\n","    dA_prev - Gradient of the cost w.r.t. A_prev\n","    dW - Gradient of the cost w.r.t. W\n","    db - Gradient of the cost w.r.t. b \n","    \"\"\"\n","    \n","    linear_cache, activation_cache = cache\n","    \n","    if activation == 'sigmoid':\n","        s = sigmoid(activation_cache)\n","        dZ = dA * s * (1-s)\n","        dA_prev, dW, db = linear_backward_propagation(dZ, linear_cache)\n","    \n","    elif activation == 'relu':\n","        dZ = np.array(dA, copy=True)\n","        dZ[activation_cache <= 0] = 0\n","        dA_prev, dW, db = linear_backward_propagation(dZ, linear_cache)\n","    \n","    elif activation == 'tanh':\n","        Z = tanh(activation_cache)\n","        dZ = 1 - Z*Z\n","        dA_prev, dW, db = linear_backward_propagation(dZ, linear_cache)\n","    \n","    elif activation == 'softmax':\n","        tmp = activation_cache.reshape((-1,1))\n","        dZ = np.diagflat(activation_cache) - np.dot(tmp, tmp.T)\n","        dA_prev, dW, db = linear_backward_propagation(dZ, linear_cache)\n","    \n","    return dA_prev, dW, db"]},{"cell_type":"code","execution_count":9,"id":"08fb8492","metadata":{"execution":{"iopub.execute_input":"2022-12-16T18:28:32.743755Z","iopub.status.busy":"2022-12-16T18:28:32.743449Z","iopub.status.idle":"2022-12-16T18:28:32.753913Z","shell.execute_reply":"2022-12-16T18:28:32.752919Z"},"papermill":{"duration":0.017775,"end_time":"2022-12-16T18:28:32.755973","exception":false,"start_time":"2022-12-16T18:28:32.738198","status":"completed"},"tags":[]},"outputs":[],"source":["def L_backward_propagation(AL, Y, caches, activation_hidden, activation_output):\n","    \"\"\"\n","    Inputs:\n","    AL - ouput of L_model_forward()\n","    Y - true label vector\n","    caches - (linear_cache, activation_cache)\n","    Returns:\n","    grads - gradients of dAl, dWl, dbl, where l is the layer number\n","    \"\"\"\n","    \n","    grads = {}\n","    L = len(caches)\n","    m = AL.shape[1]\n","    Y = Y.reshape(AL.shape) # Y is same shape as AL\n","    \n","    if activation_output == 'sigmoid':\n","        dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n","        current_cache = caches[L-1]\n","        dA_prev_temp, dW_temp, db_temp = activation_backward_propagation(dAL, current_cache, 'sigmoid')\n","        grads[\"dA\" + str(L-1)] = dA_prev_temp\n","        grads[\"dW\" + str(L)] = dW_temp\n","        grads[\"db\" + str(L)] = db_temp\n","    elif activation_output == 'softmax':\n","        dAL = AL - Y\n","        current_cache = caches[L-1]\n","        dA_prev_temp, dW_temp, db_temp = activation_backward_propagation(dAL, current_cache, 'softmax')\n","        grads[\"dA\" + str(L-1)] = dA_prev_temp\n","        grads[\"dW\" + str(L)] = dW_temp\n","        grads[\"db\" + str(L)] = db_temp\n","        \n","    for l in reversed(range(L-1)):\n","        current_cache = caches[l]\n","        dA_prev_temp, dW_temp, db_temp = activation_backward_propagation(dA_prev_temp, current_cache, activation_hidden)\n","        grads[\"dA\" + str(l)] = dA_prev_temp\n","        grads[\"dW\" + str(l + 1)] = dW_temp\n","        grads[\"db\" + str(l + 1)] = db_temp\n","        \n","    return grads"]},{"cell_type":"code","execution_count":10,"id":"102a2f58","metadata":{"execution":{"iopub.execute_input":"2022-12-16T18:28:32.76579Z","iopub.status.busy":"2022-12-16T18:28:32.765448Z","iopub.status.idle":"2022-12-16T18:28:32.772307Z","shell.execute_reply":"2022-12-16T18:28:32.771293Z"},"papermill":{"duration":0.01416,"end_time":"2022-12-16T18:28:32.774535","exception":false,"start_time":"2022-12-16T18:28:32.760375","status":"completed"},"tags":[]},"outputs":[],"source":["def update_parameters(params, grads, learning_rate):\n","    \"\"\"\n","    Inputs:\n","    params - parameters dictionary\n","    grads - gradients dictionary\n","    Returns:\n","    parameters - updated parameters dictionary\n","    \"\"\"\n","    parameters = params.copy()\n","    L = len(parameters) // 2\n","    \n","    for l in range(L):\n","        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n","        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n","    \n","    return parameters"]},{"cell_type":"markdown","id":"87a3b49c","metadata":{"papermill":{"duration":0.003753,"end_time":"2022-12-16T18:28:32.782318","exception":false,"start_time":"2022-12-16T18:28:32.778565","status":"completed"},"tags":[]},"source":["# L layer Model:\n","Using all the helper functions to create the model"]},{"cell_type":"code","execution_count":11,"id":"5e882d06","metadata":{"execution":{"iopub.execute_input":"2022-12-16T18:28:32.791522Z","iopub.status.busy":"2022-12-16T18:28:32.791195Z","iopub.status.idle":"2022-12-16T18:28:32.79873Z","shell.execute_reply":"2022-12-16T18:28:32.798003Z"},"papermill":{"duration":0.014768,"end_time":"2022-12-16T18:28:32.800832","exception":false,"start_time":"2022-12-16T18:28:32.786064","status":"completed"},"tags":[]},"outputs":[],"source":["def L_layer_model(X, Y, layers_dims, activation_hidden, activation_output, learning_rate = 0.001, num_iterations=2000, print_cost=False):\n","    \"\"\"\n","    Inputs:\n","    X - input data matrix\n","    Y - true labels vector\n","    layers_dims - list containing the input size and each layer size\n","    learning_rate - for gradient descent update\n","    num_iterations - epoch of gradient descent\n","    print_cost - prints cost of each step\n","    Returns:\n","    parameters - learnt parameters by the model\n","    \"\"\"\n","    costs = []\n","    parameters = initialize_parameters(layers_dims)\n","    \n","    for i in range(0, num_iterations):\n","        # Forward propagation\n","        AL, caches = L_forward_propagation(X, parameters, activation_hidden, activation_output)\n","        \n","        cost = compute_cost(AL, Y)\n","        \n","        grads = L_backward_propagation(AL, Y, caches, activation_hidden, activation_output)\n","        \n","        parameters = update_parameters(parameters, grads, learning_rate)\n","        \n","        if print_cost and i % 100 == 0 or i == num_iterations - 1:\n","            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n","        if i % 100 == 0 or i == num_iterations:\n","            costs.append(cost)\n","    \n","    return parameters, costs"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":8.918432,"end_time":"2022-12-16T18:28:33.424409","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-12-16T18:28:24.505977","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}